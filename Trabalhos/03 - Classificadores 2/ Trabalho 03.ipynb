{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 03 - Classificadores 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando material que será usado no trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Trabalho03 as tb\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação\n",
    "\n",
    "### 1. Implementeos seguintes métodos:\n",
    "\n",
    "a. Rede MLP para classificação\n",
    "\n",
    "    i. Apenas uma camada oculta (recebe o tamanho dessa camada como parâmetro)\n",
    "    \n",
    "    ii. Pode assumir que tem apenas um neurônio de saída\n",
    "    \n",
    "> MLPClassifier()\n",
    "    \n",
    "b. KNN\n",
    "\n",
    "    i.Recebe k como parâmetro\n",
    "    \n",
    "    ii.Usar distância euclidiana\n",
    "   \n",
    "> KNN()\n",
    "\n",
    "### 2. Usaremos a funções acurácia, plot_confusion_matrix e plot_boundaries do trabalho passado\n",
    "\n",
    "    Acurácia\n",
    "> Metrics()\n",
    "\n",
    "    plot_confusion_matrix\n",
    "> ConfusionMatrix\n",
    "\n",
    "    plot_boundaries\n",
    "> Dispersal()\n",
    "\n",
    "### 3. Implementar função k_fold(X, y, k, metodo) que execute a validação cruzada k-fold sobre o conjunto de dados X,y usando o método método reportanto o erro usando função acurácia(usar k=5).Não precisa implementar parte de valição e teste, implementar somente o fluxo principal (como está no primeiro slide sobre k-fold)\n",
    "> Validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dado\n",
    "### 1. Carregue data1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('datas/data1.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. As duas primeiras colunas são as características e a última coluna é a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, :-1]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relatório\n",
    "### 1. Reporte o que se pede usando os métodos KNN (com k = 1, 2 e 3) e MLP (como número de neurônios na camada oculta 2, 3 e 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando knn euclidiano para n = 1\n",
      "Executando knn manhattan para n = 1\n",
      "Executando knn euclidiano para n = 2\n",
      "Executando knn manhattan para n = 2\n",
      "Executando knn euclidiano para n = 3\n",
      "Executando knn manhattan para n = 3\n",
      "Executando mlp para hidden_size = 2\n",
      "Executando mlp para hidden_size = 3\n",
      "Executando mlp para hidden_size = 4\n"
     ]
    }
   ],
   "source": [
    "# Executando o KNN e o MLP\n",
    "\n",
    "k_fold = tb.Validation()\n",
    "\n",
    "# Lista para armazenar cada método criado\n",
    "\n",
    "knn_euclidian_errors = []\n",
    "knn_manhattan_errors = []\n",
    "for n in range(1,4):\n",
    "    # Usando a métrica euclidiana no knn\n",
    "    knn = tb.KNN(n_neighbors=n)\n",
    "    print('Executando knn euclidiano para n =', n)\n",
    "    knn_euclidian_errors.append(k_fold.kFold(X=X, y=y, k=5, metodo=knn))\n",
    "    \n",
    "    # Usando a métrica de manhattan no knn\n",
    "    print('Executando knn manhattan para n =', n)\n",
    "    knn = tb.KNN(n_neighbors=n, metric='manhattan')\n",
    "    knn_manhattan_errors.append(k_fold.kFold(X=X, y=y, k=5, metodo=knn))\n",
    "    \n",
    "\n",
    "mlp_errors = []\n",
    "for n in range(2,5):\n",
    "    # Valores dos hiperparametros foram os que se mostraram melhores em testes rápidos realizados\n",
    "    print('Executando mlp para hidden_size =', n)\n",
    "    mlp = tb.MLPClassifier(alpha=0.1, hiden_size=n, epoch=15)\n",
    "    mlp_errors.append(k_fold.kFold(X=X, y=y, k=5, metodo=mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. O erro do 5-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro para o knn com a métrica euclidiana\n",
      "[[0.7, 0.55, 0.8, 0.7, 0.7], [0.65, 0.75, 0.8, 0.75, 0.55], [0.7, 0.7, 0.85, 0.65, 0.6]]\n",
      "\n",
      "Erro para o knn com a métrica de manhattan\n",
      "[[0.7, 0.55, 0.8, 0.7, 0.7], [0.65, 0.75, 0.8, 0.75, 0.55], [0.7, 0.7, 0.85, 0.65, 0.6]]\n",
      "\n",
      "Erro para o mlp\n",
      "[[0.6, 0.4, 0.6, 0.55, 0.85], [0.6, 0.4, 0.6, 0.55, 0.85], [0.6, 0.4, 0.6, 0.55, 0.85]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Erro para o knn com a métrica euclidiana')\n",
    "print(knn_euclidian_errors)\n",
    "print()\n",
    "print('Erro para o knn com a métrica de manhattan')\n",
    "print(knn_manhattan_errors)\n",
    "print()\n",
    "print('Erro para o mlp')\n",
    "print(mlp_errors)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. O dado em um gráfico de dispersão com as fronteiras de separação produzidas pelo método treinado com o conjunto de dados inteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersal = tb.Dispersal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com base nos resultados acima, será criado apenas um método para ser usado nos gráficos \n",
    "# abaixo com os parâmetros que se saíram \"melhor\" de maneira geral em cada teste\n",
    "\n",
    "# Para o KNN com ambas as métricas, o resultado foi igual, portanto será usado\n",
    "# apenas um com a métrica euclidiana\n",
    "\n",
    "dknn = tb.KNN(n_neighbors=1)\n",
    "dknn.fit(X=X, y=y)\n",
    "dispersal.plot_boundaries(X=X, y=y, clf=dknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o MLP, usaremos quatro neurônios na camada oculta com um alpha de 0.01 e 15 épocas\n",
    "\n",
    "dmlp = tb.MLPClassifier(alpha=0.01, hiden_size=4, epoch=15)\n",
    "dmlp.fit(X=X, y=y)\n",
    "dispersal.plot_boundaries(X=X, y=y, clf=dmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
